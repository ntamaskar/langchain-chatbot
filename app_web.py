
import os
import streamlit as st
from langchain_openai import OpenAI

# ğŸ”‘ Get API key from environment
import streamlit as st
api_key = st.secrets["OPENAI_API_KEY"]

if not api_key:
    st.error("âš ï¸ OPENAI_API_KEY not set. Set it before running.")
    st.stop()

# ğŸ¤– Initialize OpenAI LLM
llm = OpenAI(openai_api_key=api_key, temperature=0.7, model="gpt-3.5-turbo-instruct")

# ğŸ¨ Custom CSS for better styling
st.markdown("""
    <style>
        body { background-color: #f9f9f9; }
        .stChatMessage.user { background: #e0f7fa; border-radius: 10px; padding: 10px; }
        .stChatMessage.assistant { background: #fff3e0; border-radius: 10px; padding: 10px; }
    </style>
""", unsafe_allow_html=True)

# ğŸ·ï¸ App Title
st.title("ğŸ’¬ Natty's Smart Assistant")
st.caption("Enhanced UI - LangChain + Streamlit + OpenAI")

# ğŸ§  Store chat history
if "messages" not in st.session_state:
    st.session_state.messages = []

# ğŸ–¼ï¸ Display chat history
for msg in st.session_state.messages:
    avatar = "ğŸ§‘â€ğŸ’»" if msg["role"] == "user" else "ğŸ¤–"
    with st.chat_message(msg["role"], avatar=avatar):
        st.markdown(msg["content"])

# âŒ¨ï¸ User input
user_input = st.chat_input("Ask me anything...")

if user_input:
    # Save user message
    st.session_state.messages.append({"role": "user", "content": user_input})

    # Display user message immediately
    with st.chat_message("user", avatar="ğŸ§‘â€ğŸ’»"):
        st.markdown(user_input)

    # âœ… Generate assistant response (with proper error handling)
    try:
        raw_response = llm.invoke(user_input)  # returns an object
        response = raw_response if isinstance(raw_response, str) else str(raw_response)
    except Exception as e:
        response = f"âš ï¸ Sorry, there was an error contacting OpenAI: {str(e)}"

    # Save and display assistant response
    st.session_state.messages.append({"role": "assistant", "content": response})
    with st.chat_message("assistant", avatar="ğŸ¤–"):
        st.markdown(response)
